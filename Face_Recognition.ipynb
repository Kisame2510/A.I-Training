{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlT8Ns5NNge28NyJDxX1gP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kisame2510/A.I-Training/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56bACgqEAiOA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as ses\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score,recall_score,confusion_matrix,classification_report,accuracy_score,f1_score\n",
        "\n",
        "\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization, LSTM,Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical ,load_img, img_to_array\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras import callbacks\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset():\n",
        "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "    def face_cropped(img):\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "        \n",
        "        if faces is ():\n",
        "            return None\n",
        "        for (x,y,w,h) in faces:\n",
        "            cropped_face = img[y:y+h,x:x+w]\n",
        "        return cropped_face\n",
        "    \n",
        "    cap = cv2.VideoCapture(1)\n",
        "    img_id = 0\n",
        "    \n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if face_cropped(frame) is not None:\n",
        "            img_id+=1\n",
        "            face = cv2.resize(face_cropped(frame), (200,200))\n",
        "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "            #file_name_path = \"data/\"+\"Ishwar.\"+str(img_id)+\".jpg\"\n",
        "            file_name_path = \"Images for visualization/\"+str(img_id)+'.jpg'\n",
        "            cv2.imwrite(file_name_path, face)\n",
        "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
        "            \n",
        "            cv2.imshow(\"Cropped_Face\", face)\n",
        "            if cv2.waitKey(1)==13 or int(img_id)==20:\n",
        "                break\n",
        "                \n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Collecting samples is completed !!!\")\n",
        "#generate_dataset()"
      ],
      "metadata": {
        "id": "oBZWjQGeBZaJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}